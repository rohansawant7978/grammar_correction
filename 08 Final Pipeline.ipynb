{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GDYXfQhKWbw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense,RNN,Softmax\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Softmax\n",
        "from tensorflow.keras.optimizers import Adam,Nadam\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from nltk.translate.gleu_score import sentence_gleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V1b-YteL4ms"
      },
      "source": [
        "from utility import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkHrn5TLNDvL"
      },
      "source": [
        "model = encoder_decoder(enc_vocab_size,dec_vocab_size,embedding_dim,lstm_size,input_length,batch_size,att_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y24HYU5NOsbk",
        "outputId": "322bdd94-206d-4b4b-bfe6-b035ced31daf"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/Self Case studies/CS02 Grammar Error Corrector/Models/03 enc_dec_with_attention/03_enc_dec_with_attention')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0d7d7b4250>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryNuPnadK55i"
      },
      "source": [
        "def function1(input_sentence):\n",
        "    '''This function takes sentence as input and returns a grammatically correct sentence as output'''\n",
        "    corrc_wrd_idx_dict = tokenizer_dec.word_index\n",
        "    corrc_idx_wrd_dict = {v: k for k, v in corrc_wrd_idx_dict.items()}\n",
        "\n",
        "    input_sentence = tokenizer_enc.texts_to_sequences([input_sentence])[0]\n",
        "    initial_hidden_state = tf.zeros([1,192])\n",
        "    initial_cell_state = tf.zeros([1,192])\n",
        "    encoder_initial_state = [initial_hidden_state,initial_cell_state]\n",
        "    input_sentence = tf.keras.preprocessing.sequence.pad_sequences([input_sentence],maxlen=12,padding='post')\n",
        "    input_sentence = input_sentence[0]\n",
        "    enc_output, enc_state_h, enc_state_c = model.layers[0](np.expand_dims(input_sentence,0),encoder_initial_state)\n",
        "    pred = []\n",
        "    sentence = []\n",
        "    cur_vec = np.ones((1, 1),dtype='int')\n",
        "    attention_array = np.zeros([12,12])\n",
        "    for i in range(12):\n",
        "        output,dec_state_h, dec_state_c,att_weights,context_vector = model.layers[1].onestepdecoder(cur_vec, enc_output,enc_state_h, enc_state_c)\n",
        "        enc_state_h, enc_state_c = dec_state_h, dec_state_c\n",
        "        cur_vec = np.reshape(np.argmax(output), (1, 1))\n",
        "        if corrc_idx_wrd_dict[cur_vec[0][0]] == '<end>':\n",
        "            break\n",
        "        pred.append(cur_vec[0][0])\n",
        "        att_weights = tf.squeeze(att_weights)   \n",
        "        attention_array[i] = att_weights\n",
        "    for i in pred:\n",
        "        sentence.append(corrc_idx_wrd_dict[i])\n",
        "    return \" \".join(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l9P1kdJRZhSh",
        "outputId": "7f02b6d7-16e5-462d-a4f5-c1bc05374338"
      },
      "source": [
        "function1('I heard it was the popular book in America .')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I heard it was a popular book in America .'"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73wePjQDaVpy"
      },
      "source": [
        "def function2(file):\n",
        "    df = pd.read_csv(file)\n",
        "    glue_score_arr = []\n",
        "    for i in tqdm(range(len(df))):\n",
        "        reference = [df['correct'].iloc[i].split()]\n",
        "        pred = function1(df['incorrect'].iloc[i])\n",
        "        candidate = pred.split()\n",
        "        try:\n",
        "            glue_score_arr.append(sentence_gleu(reference, candidate))\n",
        "        except:\n",
        "            continue\n",
        "    return np.mean(glue_score_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ5c5CDDaikR",
        "outputId": "4eb42bff-25d7-407b-c3d8-cad62c5294c6"
      },
      "source": [
        "function2('/content/drive/MyDrive/Self Case studies/CS02 Grammar Error Corrector/test_file.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:34<00:00,  5.76it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5706688557748922"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}